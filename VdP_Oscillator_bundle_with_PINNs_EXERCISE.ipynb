{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3548a15f",
   "metadata": {},
   "source": [
    "# Van der Pol Oscillator\n",
    "\n",
    "Now it is your turn. Use what you learned in the previous notebook exercise to solve the Van der Pol Oscillator in a bundle using PINNs.\n",
    "\n",
    "The equation for the van der pol oscillator is:\n",
    "$$\\frac{d^2 x}{dt^2} - a (1-x^2)\\frac{dx}{dt} + x = 0$$\n",
    "\n",
    "with initial Robin (mixed) conditions:\n",
    "$$x(0) = 1 \\,\\,\\,;\\,\\,\\,x'(0)=0$$\n",
    "\n",
    "Reminder: remember PINNs usually converge better when solving (systems of) 1st order ODEs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa6ec2",
   "metadata": {},
   "source": [
    "### Import the needed packages\n",
    "\n",
    "If you find a message like:\n",
    "\n",
    "\"ModuleNotFoundError: No module named '$\\texttt{package\\_name}$' \"\n",
    "\n",
    "You can install the package using:\n",
    "!pip install package_name\n",
    "\n",
    "or you can install the $\\texttt{requirements.txt}$ available in the Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a762ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from neurodiffeq.conditions import BundleIVP, IVP\n",
    "from neurodiffeq import diff\n",
    "from neurodiffeq.networks import FCNN\n",
    "from neurodiffeq.generators import BaseGenerator,Generator1D, PredefinedGenerator, MeshGenerator\n",
    "from torch import nn\n",
    "from neurodiffeq.solvers import BundleSolver1D\n",
    "from neurodiffeq.callbacks import ActionCallback \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "import math\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dfd3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install torch\n",
    "# !pip install neurodiffeq\n",
    "# !pip install -U jupyter ipywidgets\n",
    "# !pip install ipywidgets\n",
    "\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4ba044",
   "metadata": {},
   "source": [
    "### Create the equation\n",
    "\n",
    "Let us first define the equation.\n",
    "\n",
    "Note that for $\\texttt{neurodiffeq}$, the variables input to the equations have to appear in the following order:\n",
    "1. Dependent variables\n",
    "2. Independent variable\n",
    "3. (Optional) Other inputs to the equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f130df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VdP_equation(): #, k=1.0):\n",
    "\n",
    "\n",
    "    return [ ... ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebfdce4",
   "metadata": {},
   "source": [
    "### Define the BC/ICs\n",
    "\n",
    "The boundary conditions within neurodiffeq are defined as follows:\n",
    "\n",
    "- Use IVP or DirichletBVP, etc. for non-bundle IC/BC\n",
    "- Use BundleIVP, BundleDirichletBVP, etc. for bundle BC\n",
    "\n",
    "Read the docs for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a9fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f87cd",
   "metadata": {},
   "source": [
    "### Create the NNs\n",
    "\n",
    "The NNs used can be Fully Connected Neural Networks (FCNN), or they can have more exotic architectures, for which they have to be defined specifically.\n",
    "\n",
    "For our FCNN case within $\\texttt{PyTorch}$ and neurodiffeq, we can choose number of inputs, outputs, hidden layers (and neurons within each hidden layer), and activation function (see pytorch documentation for other activation functions).\n",
    "\n",
    "How many functions are we trying to predict? How many inputs does each NN (if more than one) need?\n",
    "\n",
    "You can try different activation functions to improve convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7987633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input_units =    # how many inputs does the model need?\n",
    "hidden_layers = [  ]\n",
    "\n",
    "actv = nn.Tanh\n",
    "\n",
    "nets = [FCNN(n_input_units = n_input_units, hidden_units = hidden_layers, n_output_units = 1, actv=actv) \n",
    "            for _ in range()]  # Range - how many nets do we need?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d2c0a4",
   "metadata": {},
   "source": [
    "### Define Optimizer and Scheduler\n",
    "\n",
    "The optimizer can be chosen from the ones available in $\\texttt{PyTorch}$, for example:\n",
    "- 1st order optimizers like SGD (Stochastic Gradient Descent) or $\\texttt{Adam}$ (SGD with momenta - betas, see: )\n",
    "\n",
    "If you want, you can try multiple optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21a6d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=[p for net in nets for p in net.parameters()], \n",
    "                                lr=1e-3,\n",
    "                                # betas=(0.9, 0.99))\n",
    "                                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c328d0",
   "metadata": {},
   "source": [
    "### Define specifications of the problem\n",
    "\n",
    "For how long can you obtain convergence i.e. how large can you set $t_{max}$?\n",
    "\n",
    "For how big a range of the stiffness parameter $a$ can you obtain reasonable solutions? \n",
    "\n",
    "How can you improve the convergence in both of these cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d99714",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_min = 0.0\n",
    "t_max = \n",
    "\n",
    "a_min = 1.0\n",
    "a_max = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106df14c",
   "metadata": {},
   "source": [
    "### Sample the Generators (indep. var., bundle params.) \n",
    "\n",
    "How many variables have to be sampled? How should we feed the generated points to the model?\n",
    "\n",
    "Remember: You should try different sampling methods in Generator1D! (some of them are: 'uniform', 'equally-spaced', 'equally-spaced-noisy', 'log-spaced', etc. see neurodiffeq for the whole list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = \n",
    "n_a_points = \n",
    "\n",
    "g1 = Generator1D(n_points, t_min, t_max, method = )\n",
    "\n",
    "\n",
    "train_generator = MeshGenerator(g1, ...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b69978",
   "metadata": {},
   "source": [
    "### Define the Solver\n",
    "It takes everything created up to this point and will be in charge of the training process. For the internal structure, see $\\texttt{neurodiffeq}$ bibliography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a31235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoSchedulerStep(ActionCallback):\n",
    "    def __init__(self, scheduler):\n",
    "        super().__init__()\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "    def __call__(self, solver):\n",
    "        self.scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6918972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.985)\n",
    "scheduler_cb = DoSchedulerStep(scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e655fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = BundleSolver1D(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fae25a",
   "metadata": {},
   "source": [
    "### (Optional) Load pretrained model\n",
    "This function allows to load a pretrained model into the solver model that was just generated, as long as it has been saved previously using a function as defined in the posterior subsection \"Save results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a02011b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, path):\n",
    "\n",
    "    master_dict = torch.load(path, map_location='cpu', weights_only=False)\n",
    "\n",
    "    # model.global_epoch = master_dict['epoch']\n",
    "\n",
    "    nets_architecture = master_dict['nets_architecture']\n",
    "\n",
    "    print(nets_architecture[f'net_{0}']['activations'][0])\n",
    "\n",
    "    model.nets = [FCNN(n_input_units=nets_architecture[f'net_{i}']['n_input'], \\\n",
    "                        hidden_units=nets_architecture[f'net_{i}']['hidden_layers'], \\\n",
    "                        n_output_units=nets_architecture[f'net_{i}']['n_output'], \\\n",
    "                        actv = getattr(nn, nets_architecture[f'net_{i}']['activations'][0])  # dynamic activation\n",
    "                ) for i in range(len(nets_architecture))]\n",
    "\n",
    "    for i in range(len(model.nets)):\n",
    "        model.nets[i].load_state_dict(master_dict['nets_state'][i])\n",
    "\n",
    "    model.metrics_history['train_loss'] = master_dict['train_loss']\n",
    "    model.metrics_history['valid_loss'] = master_dict['validation_loss']\n",
    "\n",
    "    print('Pretrained model sucessfully loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71ced568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_pretrained_model = f'{os.getcwd()}/results/test_1/NN_epochs_5000'\n",
    "\n",
    "# load_model(model = solver, path = path_pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1483d4e7",
   "metadata": {},
   "source": [
    "### Train the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc017ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = \n",
    "\n",
    "solver.fit(max_epochs=epochs, \n",
    "                callbacks=[scheduler_cb], \n",
    "                )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f206d",
   "metadata": {},
   "source": [
    "### Visualize the results\n",
    "\n",
    "Here we can visualize the training loss function (and validation if it exists), solutions obtained by the NN and residuals of the differential equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = solver.metrics_history['train_loss']\n",
    "\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.plot(loss, label = 'Train loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss (log scale)')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44e4430",
   "metadata": {},
   "source": [
    "#### Numerical solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1426a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_solutions = []\n",
    "\n",
    "a_values = np.linspace(a_min,a_max, 5)\n",
    "\n",
    "print('a values:', a_values)\n",
    "\n",
    "\n",
    "for k_val in a_values:\n",
    "    \n",
    "    def VdP_num_equation(t, state, a=k_val):\n",
    "\n",
    "        return [dxdt, dydt]\n",
    "    \n",
    "    # Initial conditions\n",
    "\n",
    "    x0 = \n",
    "    y0 = \n",
    "\n",
    "    t_span = (t_min, t_max)\n",
    "    t_eval = np.linspace(*t_span, 1000)\n",
    "\n",
    "    # Solve\n",
    "    num_sol = solve_ivp(VdP_num_equation, t_span, [x0, y0], t_eval=t_eval)\n",
    "\n",
    "    num_solutions.append(num_sol)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623d5d94",
   "metadata": {},
   "source": [
    "#### PINN solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d50672",
   "metadata": {},
   "outputs": [],
   "source": [
    "step=1\n",
    "best=True\n",
    "\n",
    "t = torch.linspace(t_min, t_max, 250)\n",
    "\n",
    "x_solutions = []\n",
    "y_solutions = []\n",
    "\n",
    "\n",
    "sol = solver.get_solution(best = best)\n",
    "\n",
    "for i, k_val in enumerate(a_values):\n",
    "\n",
    "    k_input = k_val*torch.ones_like(t)\n",
    "\n",
    "    x_sol, y_sol = sol(t, k_input) #, x0_input)\n",
    "\n",
    "    x_solutions.append(x_sol.cpu().detach().numpy())\n",
    "    y_solutions.append(y_sol.cpu().detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec5fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "\n",
    "for i, k_val in enumerate(a_values):\n",
    "    if i==0:\n",
    "        plt.plot(t.cpu().detach().numpy(), x_solutions[i], label=f'NN x(t)', linestyle='dashed', linewidth=1, color ='k')\n",
    "        plt.plot(t.cpu().detach().numpy(), y_solutions[i], label=f'NN y(t)',  linestyle='dashdot', linewidth=1, color ='k')\n",
    "        plt.plot(num_solutions[i].t, num_solutions[i].y[0], '-', label=f'Num x(t)',  color ='C0',linewidth=3, alpha=0.6, zorder=0)\n",
    "        plt.plot(num_solutions[i].t, num_solutions[i].y[1],'-', label=f'Num y(t)',  color ='C1', linewidth=3,alpha=0.6, zorder=0)\n",
    "    else:\n",
    "        plt.plot(t.cpu().detach().numpy(), x_solutions[i], linestyle='dashed', linewidth=1, color ='k')\n",
    "        plt.plot(t.cpu().detach().numpy(), y_solutions[i], linestyle='dashdot', linewidth=1, color ='k')\n",
    "        plt.plot(num_solutions[i].t, num_solutions[i].y[0], '-',  color ='C0',linewidth=3, alpha=0.6, zorder=0)\n",
    "        plt.plot(num_solutions[i].t, num_solutions[i].y[1],'-', color ='C1', linewidth=3,alpha=0.6, zorder=0)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('Solutions')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bed312",
   "metadata": {},
   "source": [
    "### Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53304a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "\n",
    "for i, k_val in enumerate(a_values):\n",
    "    \n",
    "    k_input = k_val*torch.ones_like(t)\n",
    "\n",
    "    res1, res2 = solver.get_residuals(t, k_input, best = False)\n",
    "\n",
    "    plt.plot(t.cpu().detach().numpy(), res1.cpu().detach().numpy(), '-', label=f'a={k_val}', color = f'C{i}', alpha = 0.7)\n",
    "    plt.plot(t.cpu().detach().numpy(), res2.cpu().detach().numpy(),'--', color = f'C{i}', alpha = 0.7)\n",
    "\n",
    "    plt.axhline(np.sqrt(solver.metrics_history['train_loss'][-1]), color='k', linestyle='dotted')\n",
    "    plt.axhline(-np.sqrt(solver.metrics_history['train_loss'][-1]), color='k', linestyle='dotted')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('Solutions')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e0cdf8",
   "metadata": {},
   "source": [
    "### Save the results (optional)\n",
    "\n",
    "This function allows us to save the current state of the PINN model. This is extremely useful as a checkpoint furing training, in case any user wants to reload a prertained model to visualize results, analize them, keep on training, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1cef2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    nets_state = []\n",
    "\n",
    "    for i in range(len(model.nets)):\n",
    "        nets_state.append(model.nets[i].state_dict())\n",
    "\n",
    "    net_architecture = {}\n",
    "\n",
    "    for j, net in enumerate(model.nets):\n",
    "        layers = net.NN\n",
    "\n",
    "        # --- Extract only linear layers for dimensions ---\n",
    "        linear_layers = [layer for layer in layers if isinstance(layer, nn.Linear)]\n",
    "\n",
    "        n_input = linear_layers[0].in_features\n",
    "        n_output = linear_layers[-1].out_features\n",
    "        hidden_layers = [layer.out_features for layer in linear_layers[1:-1]]\n",
    "\n",
    "        # --- Extract activation functions (class names) ---\n",
    "        activations = [layer.__class__.__name__ for layer in layers if not isinstance(layer, nn.Linear)]\n",
    "\n",
    "        net_architecture[f'net_{j}'] = {\n",
    "            'n_input': n_input,\n",
    "            'hidden_layers': hidden_layers,\n",
    "            'n_output': n_output,\n",
    "            'activations': activations\n",
    "        }\n",
    "    \n",
    "\n",
    "    state = {'epoch': model.global_epoch, \n",
    "            'nets_architecture': net_architecture,\n",
    "            'nets_state': nets_state,\n",
    "            'optimizer': model.optimizer.state_dict(), \n",
    "            'train_loss': model.metrics_history['train_loss'],\n",
    "            'validation_loss': model.metrics_history['valid_loss']\n",
    "        }\n",
    "\n",
    "    torch.save(state,path+'_epochs_'+str(model.global_epoch))\n",
    "    print('Model succesfully saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c210f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"VdP_test_1\"\n",
    "\n",
    "# Parent Directory path \n",
    "parent_dir = f'{os.getcwd()}/results/'\n",
    "\n",
    "# Path \n",
    "path_results = os.path.join(parent_dir, directory) \n",
    "\n",
    "if os.path.exists(path_results) == False:\n",
    "    os.makedirs(path_results) \n",
    "    print(\"New directory created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2b3a26da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model succesfully saved\n"
     ]
    }
   ],
   "source": [
    "save_model(model = solver, path=f'{path_results}/NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834895e2",
   "metadata": {},
   "source": [
    "## Bundle on the parameter $a$ and the initial condition $x(0)=x_0$\n",
    "\n",
    "Now, you can do a bundle both on the initial condition $x(0)=x_0$ and the parameter $a$ (i.e. give the model both $x_0$ and $a$ as bundle parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e59ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_conditions = [\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef845a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [16,16,16]\n",
    "\n",
    "actv = nn.Tanh\n",
    "\n",
    "new_nets = [FCNN(n_input_units = , hidden_units=hidden_layers, n_output_units=1, actv=actv) for _ in range()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc17af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=[p for net in new_nets for p in net.parameters()], \n",
    "                                lr=1e-3,\n",
    "                                # betas=(0.9, 0.99))\n",
    "                                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bacde0",
   "metadata": {},
   "source": [
    "### Define specifications of the problem\n",
    "\n",
    "Time we will be solving for, range for the IC/BCs bundle, range for the parameter's bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1adc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_min = 0.0\n",
    "t_max = \n",
    "\n",
    "a_min = 1.0\n",
    "a_max = \n",
    "\n",
    "x0_min = \n",
    "x0_max = \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311fa98c",
   "metadata": {},
   "source": [
    "### Sample and visualize the Generators (indep. var., bundle params.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b56fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = \n",
    "n_a_points = \n",
    "n_x0_points = \n",
    "\n",
    "\n",
    "\n",
    "train_generator = MeshGenerator(... , ... , ...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e28cf0",
   "metadata": {},
   "source": [
    "### Define the Solver\n",
    "It takes everything created up to this point and will be in charge of the training process. For the internal structure, see $\\texttt{neurodiffeq}$ bibliography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0594fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoSchedulerStep(ActionCallback):\n",
    "    def __init__(self, scheduler):\n",
    "        super().__init__()\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "    def __call__(self, solver):\n",
    "        self.scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd7f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.985)\n",
    "scheduler_cb = DoSchedulerStep(scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd49c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_solver = BundleSolver1D(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2bbc56",
   "metadata": {},
   "source": [
    "### (Optional) Load pretrained model\n",
    "This function allows to load a pretrained model into the solver model that was just generated, as long as it has been saved previously using a function as defined in the posterior subsection \"Save results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69afcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, path):\n",
    "\n",
    "    master_dict = torch.load(path, map_location='cpu', weights_only=False)\n",
    "\n",
    "    # model.global_epoch = master_dict['epoch']\n",
    "\n",
    "    nets_architecture = master_dict['nets_architecture']\n",
    "\n",
    "    print(nets_architecture[f'net_{0}']['activations'][0])\n",
    "\n",
    "    model.nets = [FCNN(n_input_units=nets_architecture[f'net_{i}']['n_input'], \\\n",
    "                        hidden_units=nets_architecture[f'net_{i}']['hidden_layers'], \\\n",
    "                        n_output_units=nets_architecture[f'net_{i}']['n_output'], \\\n",
    "                        actv = getattr(nn, nets_architecture[f'net_{i}']['activations'][0])  # dynamic activation\n",
    "                ) for i in range(len(nets_architecture))]\n",
    "\n",
    "    for i in range(len(model.nets)):\n",
    "        model.nets[i].load_state_dict(master_dict['nets_state'][i])\n",
    "\n",
    "    model.metrics_history['train_loss'] = master_dict['train_loss']\n",
    "    model.metrics_history['valid_loss'] = master_dict['validation_loss']\n",
    "\n",
    "    print('Pretrained model sucessfully loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a08ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_pretrained_model = f'{os.getcwd()}/results/test_1/NN_epochs_5000'\n",
    "\n",
    "# load_model(model = solver, path = path_pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc7fcbe",
   "metadata": {},
   "source": [
    "### Train the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d1af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = \n",
    "\n",
    "new_solver.fit(max_epochs=epochs, \n",
    "                callbacks=[scheduler_cb], \n",
    "                )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cab2fb",
   "metadata": {},
   "source": [
    "### Visualize the results\n",
    "\n",
    "Here we can visualize the training loss function (and validation if it exists), solutions obtained by the NN and residuals of the differential equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3154a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = new_solver.metrics_history['train_loss']\n",
    "\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.plot(loss, label = 'Train loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss (log scale)')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_solutions = []\n",
    "\n",
    "\n",
    "a_values = np.linspace(a_min,a_max, 5)\n",
    "x0_values = np.linspace(x0_min, x0_max,5)\n",
    "\n",
    "print(a_values)\n",
    "\n",
    "for k_val in a_values:\n",
    "    \n",
    "    def VdP_num_equation(t, state, a=k_val):\n",
    "        x, y = state\n",
    "        \n",
    "        ...\n",
    "\n",
    "        return [dxdt, dydt]\n",
    "    \n",
    "    for x0 in x0_values:\n",
    "\n",
    "        # Initial conditions\n",
    "        x0 = x0\n",
    "        y0 = 0.0\n",
    "        t_span = (t_min, t_max)\n",
    "        t_eval = np.linspace(*t_span, 1000)\n",
    "\n",
    "        # Solve\n",
    "        num_sol = solve_ivp(VdP_num_equation, t_span, [x0, y0], t_eval=t_eval)\n",
    "\n",
    "        num_solutions.append(num_sol)\n",
    "\n",
    "print(len(num_solutions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed60ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step=1\n",
    "save_fig=True\n",
    "best=True\n",
    "\n",
    "t = torch.linspace(t_min, t_max, 250)\n",
    "\n",
    "x_solutions = []\n",
    "y_solutions = []\n",
    "\n",
    "\n",
    "sol = new_solver.get_solution(best = best)\n",
    "\n",
    "for i, k_val in enumerate(a_values):\n",
    "\n",
    "    k_input = k_val*torch.ones_like(t)\n",
    "\n",
    "    for j, x0_val in enumerate(x0_values):\n",
    "\n",
    "        x0_input = x0_val * torch.ones_like(t)\n",
    "        x_sol, y_sol = sol(t, k_input, x0_input)\n",
    "\n",
    "        x_solutions.append(x_sol.cpu().detach().numpy())\n",
    "        y_solutions.append(y_sol.cpu().detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec226a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 3\n",
    "n_rows = math.ceil(len(a_values) / n_cols)\n",
    "\n",
    "fig, ax = plt.subplots(n_rows, n_cols, figsize=(7*n_cols, 5*n_rows))\n",
    "ax = ax.flatten()  # make it easier to index in a single loop\n",
    "\n",
    "for i, k_val in enumerate(a_values):\n",
    "    for j, x0_val in enumerate(x0_values):\n",
    "        ax[i].plot(t.cpu().detach().numpy(), x_solutions[i+j], label=f'a={k_val:.2f}, x(t)', linestyle='dashed', linewidth=1, color='k')\n",
    "        ax[i].plot(t.cpu().detach().numpy(),y_solutions[i+j],label=f'a={k_val:.2f}, y(t)',linestyle='dashed',linewidth=1,color='k'\n",
    "        )\n",
    "\n",
    "        ax[i].plot(num_solutions[i+j].t, num_solutions[i+j].y[0], '-', label=f'a={k_val:.2f}, Num x(t)', color='C0', linewidth=3, alpha=0.6, zorder=0)\n",
    "        ax[i].plot(num_solutions[i+j].t, num_solutions[i+j].y[1], '-', label=f'a={k_val:.2f}, Num y(t)', color='C1', linewidth=3, alpha=0.6, zorder=0)\n",
    "\n",
    "    ax[i].set_xlabel('t')\n",
    "    ax[i].set_ylabel('Solutions')\n",
    "    ax[i].set_title(f'k={k_val:.2f}')\n",
    "    # ax[i].legend(loc='best')\n",
    "\n",
    "# hide any empty subplots (if len(k_values) not a multiple of 3)\n",
    "for k in range(len(k_values), n_rows * n_cols):\n",
    "    fig.delaxes(ax[k])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089293b1",
   "metadata": {},
   "source": [
    "### Plot the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f9585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 3\n",
    "n_rows = math.ceil(len(a_values) / n_cols)\n",
    "\n",
    "fig, ax = plt.subplots(n_rows, n_cols, figsize=(7*n_cols, 5*n_rows))\n",
    "ax = ax.flatten()  # make it easier to index in a single loop\n",
    "\n",
    "for i, k_val in enumerate(a_values):\n",
    "\n",
    "    k_input = k_val*torch.ones_like(t)\n",
    "\n",
    "    for j, x0_val in enumerate(x0_values):\n",
    "\n",
    "        x0_input = x0_val * torch.ones_like(t)\n",
    "\n",
    "        res1, res2 = new_solver.get_residuals(t, k_input, x0_input, best = False)\n",
    "\n",
    "        ax[i].plot(t.cpu().detach().numpy(), res1.cpu().detach().numpy(), '-', color = f'C{i}', alpha = 0.7)\n",
    "        ax[i].plot(t.cpu().detach().numpy(), res2.cpu().detach().numpy(),'--', color = f'C{i}', alpha = 0.7)\n",
    "\n",
    "    ax[i].axhline(np.sqrt(new_solver.metrics_history['train_loss'][-1]), color='k', linestyle='dotted')\n",
    "    ax[i].axhline(-np.sqrt(new_solver.metrics_history['train_loss'][-1]), color='k', linestyle='dotted')\n",
    "\n",
    "    ax[i].set_title(f'k={k_val:.2f}')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d0815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_P2_ML_Lectures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
